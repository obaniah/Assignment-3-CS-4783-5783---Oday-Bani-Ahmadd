{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obaniah/Assignment-3-CS-4783-5783---Oday-Bani-Ahmadd/blob/main/Q2_AS_3_ML_CS_5783_ODAY_BANI_AHMAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten , MaxPooling2D , Dropout \n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "zntKLxcs5Xvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBR-M0V8xC8w",
        "outputId": "c6560189-cb8f-4c20-9dcc-64da0c65a180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "z7PFIsd-3ZN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(x_train[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "c1-8y15NkZzw",
        "outputId": "acaf6c47-67c8-4922-dc60-d6470ff4b337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff292dcbc50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check image shape\n",
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-DF31_uskCz",
        "outputId": "df0ba67d-abae-47ee-8cc1-443781061165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cifar10.data_path = \"data/CIFAR-10/\""
      ],
      "metadata": {
        "id": "UnFOdjfsxQIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 3.Try different hyperparameters to obtain the best accuracy on the test set. What is your \n",
        "best performance and what were the hyperparameters? "
      ],
      "metadata": {
        "id": "XEn8l3XrBKub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten , MaxPooling2D , Dropout \n",
        "\n",
        "model_1 = keras.Sequential()\n",
        "\n",
        "model_1.add(Conv2D(6, (5, 5), padding='same', strides = (1,1) ,activation='relu', input_shape=(32,32,3)))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model_1.add(Conv2D(16, (5, 5), strides=(1,1) , activation='relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model_1.add(Conv2D(120, (5, 5), strides=(1,1) , activation='relu'))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(units=84, activation='relu'))\n",
        "model_1.add(Dense(units=10, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "yFAUxx1hkS2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNjN-AOIp4bk",
        "outputId": "ef965c8d-aa48-45e9-c7eb-abca302b689d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyQHvBFMH8qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 1. What is the effect of learning rate on the training process? Which performed best?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HCaO6kxhF-ez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lr controls how quickly or slowly a neural network model learns a problem. Moreover, the amount that the weights are updated during training is referred to as the step size. in my application there was, no significance affects but the range of values to consider for the learning rate is less than 1.0 and greater than 10^-6. A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem. "
      ],
      "metadata": {
        "id": "RdDkzYHIHUot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 2. What is the effect of batch size on the training process? Which performed best?\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tjAxdG3WGKxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size controls the accuracy of the estimate of the error gradient when training neural networks. When I used a variety of batch size i noticed that with the smaller batch size the value of loss will be less  "
      ],
      "metadata": {
        "id": "RocV-jbwI71v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 3.Try different hyperparameters to obtain the best accuracy on the test set. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "What is your best performance and what were the hyperparameters? \n",
        "\n",
        "\n",
        "---\n",
        "My best output: \n",
        "learning rate=0.00001, batch = 16 acc =: 0.5507 \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nlEu6lcmGTiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Adam with the following set of epochs = 25 and the follwoing hyperparameters :\n",
        " \n",
        "                                             acc = 0.5495  \n",
        " \n",
        "learning rate=0.001 acc =:0.5429 \n",
        " \n",
        "learning rate=0.0001 acc =:0.5488 \n",
        " \n",
        "learning rate=0.0001, batch = 512 acc =: 0.5484 \n",
        " \n",
        "learning rate=0.0001, batch = 256 acc =: 0.5477 \n",
        " \n",
        "learning rate=0.0001, batch = 1028 acc =: 0.5471 the fastest \n",
        " \n",
        "learning rate=0.0001, batch = 32 acc =: 0.5462 \n",
        " \n",
        "learning rate=0.00001, batch = 16 acc =: 0.5507 \n",
        "\n"
      ],
      "metadata": {
        "id": "PXYymYDi7znZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UWYcn30eGRH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_1.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Jry95ousMp",
        "outputId": "853f14b4-7552-4607-fa6f-219bf342b3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 18s 5ms/step - loss: 1.7491 - accuracy: 0.3788 - val_loss: 1.5107 - val_accuracy: 0.4536\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4305 - accuracy: 0.4914 - val_loss: 1.4021 - val_accuracy: 0.5090\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3080 - accuracy: 0.5386 - val_loss: 1.3515 - val_accuracy: 0.5164\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2296 - accuracy: 0.5676 - val_loss: 1.2384 - val_accuracy: 0.5695\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1638 - accuracy: 0.5901 - val_loss: 1.2627 - val_accuracy: 0.5662\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1037 - accuracy: 0.6118 - val_loss: 1.3181 - val_accuracy: 0.5500\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0498 - accuracy: 0.6302 - val_loss: 1.2582 - val_accuracy: 0.5701\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0061 - accuracy: 0.6457 - val_loss: 1.2790 - val_accuracy: 0.5691\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9657 - accuracy: 0.6590 - val_loss: 1.2727 - val_accuracy: 0.5736\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9280 - accuracy: 0.6727 - val_loss: 1.3518 - val_accuracy: 0.5639\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8850 - accuracy: 0.6860 - val_loss: 1.3325 - val_accuracy: 0.5757\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8562 - accuracy: 0.6972 - val_loss: 1.5178 - val_accuracy: 0.5221\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8191 - accuracy: 0.7088 - val_loss: 1.3821 - val_accuracy: 0.5649\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7882 - accuracy: 0.7218 - val_loss: 1.4203 - val_accuracy: 0.5774\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7666 - accuracy: 0.7277 - val_loss: 1.4659 - val_accuracy: 0.5685\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7402 - accuracy: 0.7382 - val_loss: 1.5303 - val_accuracy: 0.5620\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7166 - accuracy: 0.7475 - val_loss: 1.6019 - val_accuracy: 0.5609\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6953 - accuracy: 0.7525 - val_loss: 1.6613 - val_accuracy: 0.5566\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6785 - accuracy: 0.7621 - val_loss: 1.6198 - val_accuracy: 0.5641\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6601 - accuracy: 0.7661 - val_loss: 1.7311 - val_accuracy: 0.5518\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6340 - accuracy: 0.7748 - val_loss: 1.6843 - val_accuracy: 0.5489\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6241 - accuracy: 0.7799 - val_loss: 1.8002 - val_accuracy: 0.5588\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6017 - accuracy: 0.7881 - val_loss: 1.8487 - val_accuracy: 0.5375\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5892 - accuracy: 0.7914 - val_loss: 1.9587 - val_accuracy: 0.5405\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5872 - accuracy: 0.7967 - val_loss: 1.9249 - val_accuracy: 0.5495\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff216ac8b90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate=0.001\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b-C4S7D13GJ",
        "outputId": "a4c73888-964f-4c87-8a95-11e87de2a428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5886 - accuracy: 0.7959 - val_loss: 2.0440 - val_accuracy: 0.5454\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5620 - accuracy: 0.8037 - val_loss: 1.9655 - val_accuracy: 0.5637\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5552 - accuracy: 0.8075 - val_loss: 1.9782 - val_accuracy: 0.5516\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5347 - accuracy: 0.8136 - val_loss: 2.0935 - val_accuracy: 0.5431\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5310 - accuracy: 0.8152 - val_loss: 2.0440 - val_accuracy: 0.5519\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5194 - accuracy: 0.8202 - val_loss: 2.3478 - val_accuracy: 0.5365\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5217 - accuracy: 0.8189 - val_loss: 2.2247 - val_accuracy: 0.5502\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5013 - accuracy: 0.8253 - val_loss: 2.3259 - val_accuracy: 0.5439\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5117 - accuracy: 0.8238 - val_loss: 2.2782 - val_accuracy: 0.5373\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5011 - accuracy: 0.8269 - val_loss: 2.3017 - val_accuracy: 0.5493\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4926 - accuracy: 0.8306 - val_loss: 2.1225 - val_accuracy: 0.5463\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4861 - accuracy: 0.8324 - val_loss: 2.2486 - val_accuracy: 0.5399\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4890 - accuracy: 0.8316 - val_loss: 2.4374 - val_accuracy: 0.5489\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4809 - accuracy: 0.8366 - val_loss: 2.4948 - val_accuracy: 0.5429\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4692 - accuracy: 0.8397 - val_loss: 2.6200 - val_accuracy: 0.5495\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4590 - accuracy: 0.8447 - val_loss: 2.5099 - val_accuracy: 0.5406\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4717 - accuracy: 0.8400 - val_loss: 2.5071 - val_accuracy: 0.5394\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4511 - accuracy: 0.8461 - val_loss: 2.4722 - val_accuracy: 0.5405\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4557 - accuracy: 0.8453 - val_loss: 2.8025 - val_accuracy: 0.5342\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4478 - accuracy: 0.8462 - val_loss: 2.7639 - val_accuracy: 0.5379\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4582 - accuracy: 0.8438 - val_loss: 2.7169 - val_accuracy: 0.5417\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4331 - accuracy: 0.8542 - val_loss: 2.8764 - val_accuracy: 0.5283\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4418 - accuracy: 0.8502 - val_loss: 3.1892 - val_accuracy: 0.5319\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4379 - accuracy: 0.8534 - val_loss: 3.3006 - val_accuracy: 0.5239\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4082 - accuracy: 0.8630 - val_loss: 2.8399 - val_accuracy: 0.5429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff22c1ff910>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate=0.0001\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFTDGACW5dam",
        "outputId": "d2532529-6c39-444d-a9ce-af938e72f2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2062 - accuracy: 0.9281 - val_loss: 3.3417 - val_accuracy: 0.5548\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1442 - accuracy: 0.9507 - val_loss: 3.6414 - val_accuracy: 0.5544\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1177 - accuracy: 0.9604 - val_loss: 3.9422 - val_accuracy: 0.5517\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0988 - accuracy: 0.9682 - val_loss: 4.2883 - val_accuracy: 0.5513\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0844 - accuracy: 0.9737 - val_loss: 4.5725 - val_accuracy: 0.5506\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0724 - accuracy: 0.9777 - val_loss: 4.8106 - val_accuracy: 0.5524\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 5.2364 - val_accuracy: 0.5494\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 5.5385 - val_accuracy: 0.5487\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0459 - accuracy: 0.9864 - val_loss: 5.9468 - val_accuracy: 0.5491\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0395 - accuracy: 0.9886 - val_loss: 6.3377 - val_accuracy: 0.5466\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 6.6528 - val_accuracy: 0.5492\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 6.9273 - val_accuracy: 0.5462\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 7.2080 - val_accuracy: 0.5433\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 7.5863 - val_accuracy: 0.5465\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 7.9119 - val_accuracy: 0.5459\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 8.2723 - val_accuracy: 0.5469\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 8.3926 - val_accuracy: 0.5466\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0191 - accuracy: 0.9946 - val_loss: 8.6764 - val_accuracy: 0.5460\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 8.8904 - val_accuracy: 0.5483\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 9.1040 - val_accuracy: 0.5472\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 9.3962 - val_accuracy: 0.5474\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 9.4704 - val_accuracy: 0.5468\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 9.7012 - val_accuracy: 0.5469\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 9.9647 - val_accuracy: 0.5476\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 10.1190 - val_accuracy: 0.5488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff216817210>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 512\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nh7kbVk1jNg",
        "outputId": "c3845507-14f2-4d90-afbc-4269a1ca63b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 2s 13ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 10.4090 - val_accuracy: 0.5480\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 10.6029 - val_accuracy: 0.5483\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 10.7561 - val_accuracy: 0.5482\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 10.9191 - val_accuracy: 0.5486\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 11.0444 - val_accuracy: 0.5493\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 11.2599 - val_accuracy: 0.5479\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 11.2302 - val_accuracy: 0.5493\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 11.4092 - val_accuracy: 0.5492\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 11.6037 - val_accuracy: 0.5484\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 11.7223 - val_accuracy: 0.5488\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 11.8731 - val_accuracy: 0.5481\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 11.9501 - val_accuracy: 0.5485\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 12.0630 - val_accuracy: 0.5476\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 12.2309 - val_accuracy: 0.5474\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 12.3016 - val_accuracy: 0.5482\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 12.4351 - val_accuracy: 0.5480\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 12.5984 - val_accuracy: 0.5487\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 12.5585 - val_accuracy: 0.5502\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 12.7114 - val_accuracy: 0.5502\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 12.8082 - val_accuracy: 0.5483\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 12.8563 - val_accuracy: 0.5477\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 12.9630 - val_accuracy: 0.5480\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 13.0630 - val_accuracy: 0.5455\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 13.0449 - val_accuracy: 0.5500\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 13.1811 - val_accuracy: 0.5484\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff216abe090>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 256\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 256)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGTYr-Z6ncO",
        "outputId": "214d5333-30f1-4b89-b8ae-80e79bee938f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 13.3783 - val_accuracy: 0.5491\n",
            "Epoch 2/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 13.4320 - val_accuracy: 0.5486\n",
            "Epoch 3/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 13.6317 - val_accuracy: 0.5491\n",
            "Epoch 4/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 13.7670 - val_accuracy: 0.5494\n",
            "Epoch 5/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 13.8487 - val_accuracy: 0.5497\n",
            "Epoch 6/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 13.9044 - val_accuracy: 0.5478\n",
            "Epoch 7/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 13.9386 - val_accuracy: 0.5498\n",
            "Epoch 8/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 13.9982 - val_accuracy: 0.5496\n",
            "Epoch 9/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 14.0821 - val_accuracy: 0.5496\n",
            "Epoch 10/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 14.1798 - val_accuracy: 0.5494\n",
            "Epoch 11/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 14.2591 - val_accuracy: 0.5484\n",
            "Epoch 12/25\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 14.3369 - val_accuracy: 0.5488\n",
            "Epoch 13/25\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 14.4987 - val_accuracy: 0.5489\n",
            "Epoch 14/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 14.6255 - val_accuracy: 0.5486\n",
            "Epoch 15/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 14.6458 - val_accuracy: 0.5501\n",
            "Epoch 16/25\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 14.8005 - val_accuracy: 0.5497\n",
            "Epoch 17/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 14.8092 - val_accuracy: 0.5488\n",
            "Epoch 18/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 14.3137 - val_accuracy: 0.5484\n",
            "Epoch 19/25\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 14.2833 - val_accuracy: 0.5481\n",
            "Epoch 20/25\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 14.3875 - val_accuracy: 0.5478\n",
            "Epoch 21/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 14.4533 - val_accuracy: 0.5473\n",
            "Epoch 22/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 14.5035 - val_accuracy: 0.5477\n",
            "Epoch 23/25\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 14.5757 - val_accuracy: 0.5480\n",
            "Epoch 24/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 14.6155 - val_accuracy: 0.5478\n",
            "Epoch 25/25\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 14.6672 - val_accuracy: 0.5477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff2164e1550>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 1028\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 1028)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kldq_VkuAh7H",
        "outputId": "8524d097-dbd5-4f62-ac4d-34b67a910e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "49/49 [==============================] - 2s 27ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 14.9234 - val_accuracy: 0.5466\n",
            "Epoch 2/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 14.9558 - val_accuracy: 0.5473\n",
            "Epoch 3/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 15.0701 - val_accuracy: 0.5485\n",
            "Epoch 4/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 15.2027 - val_accuracy: 0.5478\n",
            "Epoch 5/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 15.2956 - val_accuracy: 0.5504\n",
            "Epoch 6/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 15.4183 - val_accuracy: 0.5489\n",
            "Epoch 7/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.5454 - val_accuracy: 0.5486\n",
            "Epoch 8/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.6600 - val_accuracy: 0.5469\n",
            "Epoch 9/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.6441 - val_accuracy: 0.5482\n",
            "Epoch 10/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.5713 - val_accuracy: 0.5490\n",
            "Epoch 11/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 15.4730 - val_accuracy: 0.5520\n",
            "Epoch 12/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 15.5117 - val_accuracy: 0.5483\n",
            "Epoch 13/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 15.6287 - val_accuracy: 0.5476\n",
            "Epoch 14/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 15.5266 - val_accuracy: 0.5481\n",
            "Epoch 15/25\n",
            "49/49 [==============================] - 1s 16ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 15.6236 - val_accuracy: 0.5474\n",
            "Epoch 16/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.6793 - val_accuracy: 0.5485\n",
            "Epoch 17/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.7379 - val_accuracy: 0.5477\n",
            "Epoch 18/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.7818 - val_accuracy: 0.5488\n",
            "Epoch 19/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.8312 - val_accuracy: 0.5472\n",
            "Epoch 20/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.8755 - val_accuracy: 0.5477\n",
            "Epoch 21/25\n",
            "49/49 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.9104 - val_accuracy: 0.5477\n",
            "Epoch 22/25\n",
            "49/49 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 15.9219 - val_accuracy: 0.5476\n",
            "Epoch 23/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 16.0006 - val_accuracy: 0.5471\n",
            "Epoch 24/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 16.0188 - val_accuracy: 0.5475\n",
            "Epoch 25/25\n",
            "49/49 [==============================] - 1s 15ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 16.0650 - val_accuracy: 0.5471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff216380610>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 32\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyV-xefDJqPF",
        "outputId": "c7713d92-0a6b-4652-ef3d-ebfbf67fb586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 15.4923 - val_accuracy: 0.5433\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 15.6614 - val_accuracy: 0.5419\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 15.4636 - val_accuracy: 0.5457\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 15.0692 - val_accuracy: 0.5457\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 15.2980 - val_accuracy: 0.5426\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 15.1886 - val_accuracy: 0.5475\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 15.3779 - val_accuracy: 0.5448\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 15.3463 - val_accuracy: 0.5441\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 15.4429 - val_accuracy: 0.5480\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 15.4163 - val_accuracy: 0.5443\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 15.3556 - val_accuracy: 0.5475\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 15.3610 - val_accuracy: 0.5489\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 15.4686 - val_accuracy: 0.5482\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 15.4673 - val_accuracy: 0.5474\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 15.4950 - val_accuracy: 0.5473\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 15.2826 - val_accuracy: 0.5488\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 15.3453 - val_accuracy: 0.5463\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 15.3251 - val_accuracy: 0.5475\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 15.3856 - val_accuracy: 0.5482\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 15.6517 - val_accuracy: 0.5442\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 15.3058 - val_accuracy: 0.5477\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 15.6354 - val_accuracy: 0.5505\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 15.9554 - val_accuracy: 0.5439\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 15.7005 - val_accuracy: 0.5484\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 15.5200 - val_accuracy: 0.5462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff2162b3350>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 16\n",
        "#learning_rate=0.00001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tghRoQI7KWr2",
        "outputId": "1935ac46-4d78-4703-b307-7c12788b30b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 15.7184 - val_accuracy: 0.5496\n",
            "Epoch 2/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 15.8165 - val_accuracy: 0.5484\n",
            "Epoch 3/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 16.0614 - val_accuracy: 0.5491\n",
            "Epoch 4/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 16.2479 - val_accuracy: 0.5491\n",
            "Epoch 5/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 16.3581 - val_accuracy: 0.5496\n",
            "Epoch 6/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 16.6217 - val_accuracy: 0.5496\n",
            "Epoch 7/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 16.7905 - val_accuracy: 0.5492\n",
            "Epoch 8/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 16.8642 - val_accuracy: 0.5501\n",
            "Epoch 9/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 16.9462 - val_accuracy: 0.5493\n",
            "Epoch 10/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 17.1821 - val_accuracy: 0.5495\n",
            "Epoch 11/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 17.1522 - val_accuracy: 0.5509\n",
            "Epoch 12/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 17.3356 - val_accuracy: 0.5486\n",
            "Epoch 13/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 17.3540 - val_accuracy: 0.5494\n",
            "Epoch 14/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 17.4274 - val_accuracy: 0.5494\n",
            "Epoch 15/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 17.5911 - val_accuracy: 0.5503\n",
            "Epoch 16/25\n",
            "3125/3125 [==============================] - 13s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 17.6943 - val_accuracy: 0.5505\n",
            "Epoch 17/25\n",
            "3125/3125 [==============================] - 13s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 17.8467 - val_accuracy: 0.5501\n",
            "Epoch 18/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 17.7376 - val_accuracy: 0.5499\n",
            "Epoch 19/25\n",
            "3125/3125 [==============================] - 13s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 18.0845 - val_accuracy: 0.5489\n",
            "Epoch 20/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 18.0656 - val_accuracy: 0.5495\n",
            "Epoch 21/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 18.2928 - val_accuracy: 0.5485\n",
            "Epoch 22/25\n",
            "3125/3125 [==============================] - 14s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 18.1791 - val_accuracy: 0.5500\n",
            "Epoch 23/25\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 18.1983 - val_accuracy: 0.5504\n",
            "Epoch 24/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 18.3977 - val_accuracy: 0.5506\n",
            "Epoch 25/25\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 18.3126 - val_accuracy: 0.5507\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff21621a450>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2 4. Implement an equivalent feed forward network for the same task with each hidden layer \n",
        "containing the same number of neurons as the number of filters in each convolution layer. \n",
        "Use the Adam optimizer to train your network on the CIFAR-10 dataset for a fixed set of \n",
        "25  epochs.  Compare  its  performance  with  your  LeNet  implementation  based  on  the \n",
        "following questions: "
      ],
      "metadata": {
        "id": "5DjeErQ_AXM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "1.    What is its performance? \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "best performance with batch size 512 as the acc = 0.3264 per my trail. \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "2.    How  many  parameters  are  there  in  this  network  compared  to  the  LeNet implementation? Are they worth it? \n",
        "\n",
        "---\n",
        "\n",
        "*   At this model the Total params: 872,510 Trainable params: 872,510 non-trainable params: 0\n",
        "\n",
        "\n",
        "*   At LeNet Total params: 92,246 Trainable params: 92,246 non-trainable params: 0 \n",
        "\n",
        "*   It is not worth to have such and huge amount of params especially that the accuracy is less in these feedforward network. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IoapvNmOCt4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten , MaxPooling2D  \n",
        "\n",
        "input_shape=(32,32,3)\n",
        "model_fd = keras.Sequential()\n",
        "keras.Input(input_shape)\n",
        "model_fd.add(Dense(units=6, activation='relu'))\n",
        "model_fd.add(Dense(units=16, activation='relu'))\n",
        "model_fd.add(Dense(units=120, activation='relu'))\n",
        "model_fd.add(Dense(units=84, activation='relu'))\n",
        "model_fd.add(Flatten())\n",
        "model_fd.add(Dense(units=10, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "1Nssktboufky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_fd.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_fd.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)\n",
        "model_fd.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vxXJ8uzC7I6",
        "outputId": "d86a9290-f0c5-4253-e425-3ad652ed9aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.8643 - accuracy: 0.7092 - val_loss: 6.9721 - val_accuracy: 0.3080\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8223 - accuracy: 0.7220 - val_loss: 7.6435 - val_accuracy: 0.2968\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.8130 - accuracy: 0.7256 - val_loss: 7.8983 - val_accuracy: 0.3035\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8026 - accuracy: 0.7292 - val_loss: 7.7283 - val_accuracy: 0.2983\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.7932 - accuracy: 0.7320 - val_loss: 8.4103 - val_accuracy: 0.3015\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.7958 - accuracy: 0.7348 - val_loss: 8.0144 - val_accuracy: 0.2925\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.7859 - accuracy: 0.7382 - val_loss: 8.5888 - val_accuracy: 0.3024\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7830 - accuracy: 0.7414 - val_loss: 8.6948 - val_accuracy: 0.3014\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7560 - accuracy: 0.7481 - val_loss: 9.2582 - val_accuracy: 0.2972\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7522 - accuracy: 0.7497 - val_loss: 9.5109 - val_accuracy: 0.2930\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7484 - accuracy: 0.7520 - val_loss: 9.6238 - val_accuracy: 0.2965\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.7316 - accuracy: 0.7554 - val_loss: 9.4142 - val_accuracy: 0.2919\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 0.7195 - accuracy: 0.7610 - val_loss: 10.5247 - val_accuracy: 0.2919\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7018 - accuracy: 0.7666 - val_loss: 10.6551 - val_accuracy: 0.2975\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.7024 - accuracy: 0.7667 - val_loss: 10.6627 - val_accuracy: 0.2839\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6995 - accuracy: 0.7688 - val_loss: 10.8578 - val_accuracy: 0.2868\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6919 - accuracy: 0.7715 - val_loss: 10.6962 - val_accuracy: 0.2914\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6904 - accuracy: 0.7743 - val_loss: 10.6356 - val_accuracy: 0.2902\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6751 - accuracy: 0.7765 - val_loss: 11.4145 - val_accuracy: 0.2939\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7179 - accuracy: 0.7688 - val_loss: 11.1242 - val_accuracy: 0.2867\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6520 - accuracy: 0.7849 - val_loss: 11.5645 - val_accuracy: 0.2888\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6454 - accuracy: 0.7859 - val_loss: 12.1237 - val_accuracy: 0.2805\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6449 - accuracy: 0.7847 - val_loss: 12.5719 - val_accuracy: 0.2868\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6261 - accuracy: 0.7913 - val_loss: 12.5267 - val_accuracy: 0.2856\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.6737 - accuracy: 0.7835 - val_loss: 11.9818 - val_accuracy: 0.2867\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 32, 32, 6)         24        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32, 32, 16)        112       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32, 32, 120)       2040      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32, 32, 84)        10164     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 86016)             0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                860170    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 872,510\n",
            "Trainable params: 872,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_fd.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_fd.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25 , batch_size= 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Otm4BBzoJub",
        "outputId": "b9a481bf-331c-47b9-c35a-979e59a62e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 7s 69ms/step - loss: 2.1961 - accuracy: 0.1953 - val_loss: 2.1907 - val_accuracy: 0.2195\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.1290 - accuracy: 0.2316 - val_loss: 2.2296 - val_accuracy: 0.1682\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.1287 - accuracy: 0.2151 - val_loss: 2.2641 - val_accuracy: 0.1669\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.0774 - accuracy: 0.2538 - val_loss: 2.1403 - val_accuracy: 0.2715\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.0504 - accuracy: 0.2609 - val_loss: 2.2278 - val_accuracy: 0.2307\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.9478 - accuracy: 0.3174 - val_loss: 2.2171 - val_accuracy: 0.2532\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.0767 - accuracy: 0.2262 - val_loss: 2.3850 - val_accuracy: 0.1466\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 2.0780 - accuracy: 0.2177 - val_loss: 2.3970 - val_accuracy: 0.1617\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 2.0375 - accuracy: 0.2421 - val_loss: 2.4380 - val_accuracy: 0.1888\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.9609 - accuracy: 0.2887 - val_loss: 2.4978 - val_accuracy: 0.1663\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.9070 - accuracy: 0.3151 - val_loss: 2.4330 - val_accuracy: 0.2408\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.8359 - accuracy: 0.3476 - val_loss: 2.4962 - val_accuracy: 0.2494\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.7537 - accuracy: 0.3869 - val_loss: 2.5213 - val_accuracy: 0.2648\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.7604 - accuracy: 0.3803 - val_loss: 2.6017 - val_accuracy: 0.2471\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.6940 - accuracy: 0.4100 - val_loss: 2.5876 - val_accuracy: 0.2669\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 7s 67ms/step - loss: 1.7415 - accuracy: 0.3867 - val_loss: 2.6699 - val_accuracy: 0.2630\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 1.6908 - accuracy: 0.4098 - val_loss: 2.6572 - val_accuracy: 0.2798\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 1.6763 - accuracy: 0.4157 - val_loss: 2.8056 - val_accuracy: 0.2664\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 1.6358 - accuracy: 0.4329 - val_loss: 2.7634 - val_accuracy: 0.2829\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 1.6373 - accuracy: 0.4297 - val_loss: 2.9003 - val_accuracy: 0.2810\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 1.5919 - accuracy: 0.4462 - val_loss: 2.9934 - val_accuracy: 0.2845\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 7s 68ms/step - loss: 1.5747 - accuracy: 0.4545 - val_loss: 3.1289 - val_accuracy: 0.2815\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 7s 70ms/step - loss: 1.5520 - accuracy: 0.4674 - val_loss: 3.0793 - val_accuracy: 0.2883\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 7s 73ms/step - loss: 1.5426 - accuracy: 0.4681 - val_loss: 3.0807 - val_accuracy: 0.2844\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 7s 71ms/step - loss: 1.4440 - accuracy: 0.5061 - val_loss: 3.1310 - val_accuracy: 0.3264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff202bf2f90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_fd.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_fd.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25 , batch_size= 1028)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76LTRUqfC4cd",
        "outputId": "fdd83412-0c22-45b9-cbab-07653938184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "49/49 [==============================] - 7s 131ms/step - loss: 1.5542 - accuracy: 0.4542 - val_loss: 3.2161 - val_accuracy: 0.3181\n",
            "Epoch 2/25\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 1.3815 - accuracy: 0.5266 - val_loss: 3.3620 - val_accuracy: 0.3081\n",
            "Epoch 3/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.3598 - accuracy: 0.5350 - val_loss: 3.2929 - val_accuracy: 0.3288\n",
            "Epoch 4/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.3296 - accuracy: 0.5450 - val_loss: 3.4378 - val_accuracy: 0.3319\n",
            "Epoch 5/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.3090 - accuracy: 0.5543 - val_loss: 3.5957 - val_accuracy: 0.3332\n",
            "Epoch 6/25\n",
            "49/49 [==============================] - 6s 125ms/step - loss: 1.3242 - accuracy: 0.5491 - val_loss: 3.6434 - val_accuracy: 0.3199\n",
            "Epoch 7/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.3150 - accuracy: 0.5522 - val_loss: 3.6315 - val_accuracy: 0.3167\n",
            "Epoch 8/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.2998 - accuracy: 0.5571 - val_loss: 3.6750 - val_accuracy: 0.3236\n",
            "Epoch 9/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.2776 - accuracy: 0.5666 - val_loss: 3.7925 - val_accuracy: 0.3279\n",
            "Epoch 10/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.2566 - accuracy: 0.5697 - val_loss: 3.7918 - val_accuracy: 0.3327\n",
            "Epoch 11/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.2270 - accuracy: 0.5820 - val_loss: 3.8800 - val_accuracy: 0.3337\n",
            "Epoch 12/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.2082 - accuracy: 0.5884 - val_loss: 4.0746 - val_accuracy: 0.3254\n",
            "Epoch 13/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.1880 - accuracy: 0.5975 - val_loss: 4.1353 - val_accuracy: 0.3350\n",
            "Epoch 14/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.1782 - accuracy: 0.6012 - val_loss: 4.1960 - val_accuracy: 0.3304\n",
            "Epoch 15/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.1730 - accuracy: 0.6060 - val_loss: 4.2666 - val_accuracy: 0.3179\n",
            "Epoch 16/25\n",
            "49/49 [==============================] - 6s 126ms/step - loss: 1.1772 - accuracy: 0.6026 - val_loss: 4.2465 - val_accuracy: 0.3300\n",
            "Epoch 17/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.1414 - accuracy: 0.6147 - val_loss: 4.3073 - val_accuracy: 0.3211\n",
            "Epoch 18/25\n",
            "49/49 [==============================] - 6s 127ms/step - loss: 1.1207 - accuracy: 0.6204 - val_loss: 4.5009 - val_accuracy: 0.3197\n",
            "Epoch 19/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.1063 - accuracy: 0.6257 - val_loss: 4.6239 - val_accuracy: 0.3271\n",
            "Epoch 20/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.0941 - accuracy: 0.6293 - val_loss: 4.6379 - val_accuracy: 0.3280\n",
            "Epoch 21/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.0731 - accuracy: 0.6379 - val_loss: 4.7933 - val_accuracy: 0.3293\n",
            "Epoch 22/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.0611 - accuracy: 0.6427 - val_loss: 4.9206 - val_accuracy: 0.3157\n",
            "Epoch 23/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.0508 - accuracy: 0.6472 - val_loss: 5.0352 - val_accuracy: 0.3168\n",
            "Epoch 24/25\n",
            "49/49 [==============================] - 6s 129ms/step - loss: 1.0444 - accuracy: 0.6473 - val_loss: 5.0937 - val_accuracy: 0.3230\n",
            "Epoch 25/25\n",
            "49/49 [==============================] - 6s 128ms/step - loss: 1.0384 - accuracy: 0.6535 - val_loss: 5.0147 - val_accuracy: 0.3177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff21651efd0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}