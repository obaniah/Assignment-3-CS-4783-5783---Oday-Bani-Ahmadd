{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXG4Ol6sli3+fthUK31PuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obaniah/Assignment-3-CS-4783-5783---Oday-Bani-Ahmadd/blob/main/Q2_AS_3_ML_CS_5783_ODAY_BANI_AHMAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten , MaxPooling2D , Dropout \n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "zntKLxcs5Xvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBR-M0V8xC8w",
        "outputId": "ef04aa67-f4fa-417e-d91f-267e197114a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[ 59,  62,  63],\n",
              "           [ 43,  46,  45],\n",
              "           [ 50,  48,  43],\n",
              "           ...,\n",
              "           [158, 132, 108],\n",
              "           [152, 125, 102],\n",
              "           [148, 124, 103]],\n",
              "  \n",
              "          [[ 16,  20,  20],\n",
              "           [  0,   0,   0],\n",
              "           [ 18,   8,   0],\n",
              "           ...,\n",
              "           [123,  88,  55],\n",
              "           [119,  83,  50],\n",
              "           [122,  87,  57]],\n",
              "  \n",
              "          [[ 25,  24,  21],\n",
              "           [ 16,   7,   0],\n",
              "           [ 49,  27,   8],\n",
              "           ...,\n",
              "           [118,  84,  50],\n",
              "           [120,  84,  50],\n",
              "           [109,  73,  42]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[208, 170,  96],\n",
              "           [201, 153,  34],\n",
              "           [198, 161,  26],\n",
              "           ...,\n",
              "           [160, 133,  70],\n",
              "           [ 56,  31,   7],\n",
              "           [ 53,  34,  20]],\n",
              "  \n",
              "          [[180, 139,  96],\n",
              "           [173, 123,  42],\n",
              "           [186, 144,  30],\n",
              "           ...,\n",
              "           [184, 148,  94],\n",
              "           [ 97,  62,  34],\n",
              "           [ 83,  53,  34]],\n",
              "  \n",
              "          [[177, 144, 116],\n",
              "           [168, 129,  94],\n",
              "           [179, 142,  87],\n",
              "           ...,\n",
              "           [216, 184, 140],\n",
              "           [151, 118,  84],\n",
              "           [123,  92,  72]]],\n",
              "  \n",
              "  \n",
              "         [[[154, 177, 187],\n",
              "           [126, 137, 136],\n",
              "           [105, 104,  95],\n",
              "           ...,\n",
              "           [ 91,  95,  71],\n",
              "           [ 87,  90,  71],\n",
              "           [ 79,  81,  70]],\n",
              "  \n",
              "          [[140, 160, 169],\n",
              "           [145, 153, 154],\n",
              "           [125, 125, 118],\n",
              "           ...,\n",
              "           [ 96,  99,  78],\n",
              "           [ 77,  80,  62],\n",
              "           [ 71,  73,  61]],\n",
              "  \n",
              "          [[140, 155, 164],\n",
              "           [139, 146, 149],\n",
              "           [115, 115, 112],\n",
              "           ...,\n",
              "           [ 79,  82,  64],\n",
              "           [ 68,  70,  55],\n",
              "           [ 67,  69,  55]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[175, 167, 166],\n",
              "           [156, 154, 160],\n",
              "           [154, 160, 170],\n",
              "           ...,\n",
              "           [ 42,  34,  36],\n",
              "           [ 61,  53,  57],\n",
              "           [ 93,  83,  91]],\n",
              "  \n",
              "          [[165, 154, 128],\n",
              "           [156, 152, 130],\n",
              "           [159, 161, 142],\n",
              "           ...,\n",
              "           [103,  93,  96],\n",
              "           [123, 114, 120],\n",
              "           [131, 121, 131]],\n",
              "  \n",
              "          [[163, 148, 120],\n",
              "           [158, 148, 122],\n",
              "           [163, 156, 133],\n",
              "           ...,\n",
              "           [143, 133, 139],\n",
              "           [143, 134, 142],\n",
              "           [143, 133, 144]]],\n",
              "  \n",
              "  \n",
              "         [[[255, 255, 255],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           ...,\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           ...,\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           ...,\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[113, 120, 112],\n",
              "           [111, 118, 111],\n",
              "           [105, 112, 106],\n",
              "           ...,\n",
              "           [ 72,  81,  80],\n",
              "           [ 72,  80,  79],\n",
              "           [ 72,  80,  79]],\n",
              "  \n",
              "          [[111, 118, 110],\n",
              "           [104, 111, 104],\n",
              "           [ 99, 106,  98],\n",
              "           ...,\n",
              "           [ 68,  75,  73],\n",
              "           [ 70,  76,  75],\n",
              "           [ 78,  84,  82]],\n",
              "  \n",
              "          [[106, 113, 105],\n",
              "           [ 99, 106,  98],\n",
              "           [ 95, 102,  94],\n",
              "           ...,\n",
              "           [ 78,  85,  83],\n",
              "           [ 79,  85,  83],\n",
              "           [ 80,  86,  84]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 35, 178, 235],\n",
              "           [ 40, 176, 239],\n",
              "           [ 42, 176, 241],\n",
              "           ...,\n",
              "           [ 99, 177, 219],\n",
              "           [ 79, 147, 197],\n",
              "           [ 89, 148, 189]],\n",
              "  \n",
              "          [[ 57, 182, 234],\n",
              "           [ 44, 184, 250],\n",
              "           [ 50, 183, 240],\n",
              "           ...,\n",
              "           [156, 182, 200],\n",
              "           [141, 177, 206],\n",
              "           [116, 149, 175]],\n",
              "  \n",
              "          [[ 98, 197, 237],\n",
              "           [ 64, 189, 252],\n",
              "           [ 69, 192, 245],\n",
              "           ...,\n",
              "           [188, 195, 206],\n",
              "           [119, 135, 147],\n",
              "           [ 61,  79,  90]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 73,  79,  77],\n",
              "           [ 53,  63,  68],\n",
              "           [ 54,  68,  80],\n",
              "           ...,\n",
              "           [ 17,  40,  64],\n",
              "           [ 21,  36,  51],\n",
              "           [ 33,  48,  49]],\n",
              "  \n",
              "          [[ 61,  68,  75],\n",
              "           [ 55,  70,  86],\n",
              "           [ 57,  79, 103],\n",
              "           ...,\n",
              "           [ 24,  48,  72],\n",
              "           [ 17,  35,  53],\n",
              "           [  7,  23,  32]],\n",
              "  \n",
              "          [[ 44,  56,  73],\n",
              "           [ 46,  66,  88],\n",
              "           [ 49,  77, 105],\n",
              "           ...,\n",
              "           [ 27,  52,  77],\n",
              "           [ 21,  43,  66],\n",
              "           [ 12,  31,  50]]],\n",
              "  \n",
              "  \n",
              "         [[[189, 211, 240],\n",
              "           [186, 208, 236],\n",
              "           [185, 207, 235],\n",
              "           ...,\n",
              "           [175, 195, 224],\n",
              "           [172, 194, 222],\n",
              "           [169, 194, 220]],\n",
              "  \n",
              "          [[194, 210, 239],\n",
              "           [191, 207, 236],\n",
              "           [190, 206, 235],\n",
              "           ...,\n",
              "           [173, 192, 220],\n",
              "           [171, 191, 218],\n",
              "           [167, 190, 216]],\n",
              "  \n",
              "          [[208, 219, 244],\n",
              "           [205, 216, 240],\n",
              "           [204, 215, 239],\n",
              "           ...,\n",
              "           [175, 191, 217],\n",
              "           [172, 190, 216],\n",
              "           [169, 191, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[207, 199, 181],\n",
              "           [203, 195, 175],\n",
              "           [203, 196, 173],\n",
              "           ...,\n",
              "           [135, 132, 127],\n",
              "           [162, 158, 150],\n",
              "           [168, 163, 151]],\n",
              "  \n",
              "          [[198, 190, 170],\n",
              "           [189, 181, 159],\n",
              "           [180, 172, 147],\n",
              "           ...,\n",
              "           [178, 171, 160],\n",
              "           [175, 169, 156],\n",
              "           [175, 169, 154]],\n",
              "  \n",
              "          [[198, 189, 173],\n",
              "           [189, 181, 162],\n",
              "           [178, 170, 149],\n",
              "           ...,\n",
              "           [195, 184, 169],\n",
              "           [196, 189, 171],\n",
              "           [195, 190, 171]]],\n",
              "  \n",
              "  \n",
              "         [[[229, 229, 239],\n",
              "           [236, 237, 247],\n",
              "           [234, 236, 247],\n",
              "           ...,\n",
              "           [217, 219, 233],\n",
              "           [221, 223, 234],\n",
              "           [222, 223, 233]],\n",
              "  \n",
              "          [[222, 221, 229],\n",
              "           [239, 239, 249],\n",
              "           [233, 234, 246],\n",
              "           ...,\n",
              "           [223, 223, 236],\n",
              "           [227, 228, 238],\n",
              "           [210, 211, 220]],\n",
              "  \n",
              "          [[213, 206, 211],\n",
              "           [234, 232, 239],\n",
              "           [231, 233, 244],\n",
              "           ...,\n",
              "           [220, 220, 232],\n",
              "           [220, 219, 232],\n",
              "           [202, 203, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[150, 143, 135],\n",
              "           [140, 135, 127],\n",
              "           [132, 127, 120],\n",
              "           ...,\n",
              "           [224, 222, 218],\n",
              "           [230, 228, 225],\n",
              "           [241, 241, 238]],\n",
              "  \n",
              "          [[137, 132, 126],\n",
              "           [130, 127, 120],\n",
              "           [125, 121, 115],\n",
              "           ...,\n",
              "           [181, 180, 178],\n",
              "           [202, 201, 198],\n",
              "           [212, 211, 207]],\n",
              "  \n",
              "          [[122, 119, 114],\n",
              "           [118, 116, 110],\n",
              "           [120, 116, 111],\n",
              "           ...,\n",
              "           [179, 177, 173],\n",
              "           [164, 164, 162],\n",
              "           [163, 163, 161]]]], dtype=uint8), array([[6],\n",
              "         [9],\n",
              "         [9],\n",
              "         ...,\n",
              "         [9],\n",
              "         [1],\n",
              "         [1]], dtype=uint8)), (array([[[[158, 112,  49],\n",
              "           [159, 111,  47],\n",
              "           [165, 116,  51],\n",
              "           ...,\n",
              "           [137,  95,  36],\n",
              "           [126,  91,  36],\n",
              "           [116,  85,  33]],\n",
              "  \n",
              "          [[152, 112,  51],\n",
              "           [151, 110,  40],\n",
              "           [159, 114,  45],\n",
              "           ...,\n",
              "           [136,  95,  31],\n",
              "           [125,  91,  32],\n",
              "           [119,  88,  34]],\n",
              "  \n",
              "          [[151, 110,  47],\n",
              "           [151, 109,  33],\n",
              "           [158, 111,  36],\n",
              "           ...,\n",
              "           [139,  98,  34],\n",
              "           [130,  95,  34],\n",
              "           [120,  89,  33]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 68, 124, 177],\n",
              "           [ 42, 100, 148],\n",
              "           [ 31,  88, 137],\n",
              "           ...,\n",
              "           [ 38,  97, 146],\n",
              "           [ 13,  64, 108],\n",
              "           [ 40,  85, 127]],\n",
              "  \n",
              "          [[ 61, 116, 168],\n",
              "           [ 49, 102, 148],\n",
              "           [ 35,  85, 132],\n",
              "           ...,\n",
              "           [ 26,  82, 130],\n",
              "           [ 29,  82, 126],\n",
              "           [ 20,  64, 107]],\n",
              "  \n",
              "          [[ 54, 107, 160],\n",
              "           [ 56, 105, 149],\n",
              "           [ 45,  89, 132],\n",
              "           ...,\n",
              "           [ 24,  77, 124],\n",
              "           [ 34,  84, 129],\n",
              "           [ 21,  67, 110]]],\n",
              "  \n",
              "  \n",
              "         [[[235, 235, 235],\n",
              "           [231, 231, 231],\n",
              "           [232, 232, 232],\n",
              "           ...,\n",
              "           [233, 233, 233],\n",
              "           [233, 233, 233],\n",
              "           [232, 232, 232]],\n",
              "  \n",
              "          [[238, 238, 238],\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           ...,\n",
              "           [236, 236, 236],\n",
              "           [236, 236, 236],\n",
              "           [235, 235, 235]],\n",
              "  \n",
              "          [[237, 237, 237],\n",
              "           [234, 234, 234],\n",
              "           [234, 234, 234],\n",
              "           ...,\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           [234, 234, 234]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 87,  99,  89],\n",
              "           [ 43,  51,  37],\n",
              "           [ 19,  23,  11],\n",
              "           ...,\n",
              "           [169, 184, 179],\n",
              "           [182, 197, 193],\n",
              "           [188, 202, 201]],\n",
              "  \n",
              "          [[ 82,  96,  82],\n",
              "           [ 46,  57,  36],\n",
              "           [ 36,  44,  22],\n",
              "           ...,\n",
              "           [174, 189, 183],\n",
              "           [185, 200, 196],\n",
              "           [187, 202, 200]],\n",
              "  \n",
              "          [[ 85, 101,  83],\n",
              "           [ 62,  75,  48],\n",
              "           [ 58,  67,  38],\n",
              "           ...,\n",
              "           [168, 183, 178],\n",
              "           [180, 195, 191],\n",
              "           [186, 200, 199]]],\n",
              "  \n",
              "  \n",
              "         [[[158, 190, 222],\n",
              "           [158, 187, 218],\n",
              "           [139, 166, 194],\n",
              "           ...,\n",
              "           [228, 231, 234],\n",
              "           [237, 239, 243],\n",
              "           [238, 241, 246]],\n",
              "  \n",
              "          [[170, 200, 229],\n",
              "           [172, 199, 226],\n",
              "           [151, 176, 201],\n",
              "           ...,\n",
              "           [232, 232, 236],\n",
              "           [246, 246, 250],\n",
              "           [246, 247, 251]],\n",
              "  \n",
              "          [[174, 201, 225],\n",
              "           [176, 200, 222],\n",
              "           [157, 179, 199],\n",
              "           ...,\n",
              "           [230, 229, 232],\n",
              "           [250, 249, 251],\n",
              "           [245, 244, 247]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 31,  40,  45],\n",
              "           [ 30,  39,  44],\n",
              "           [ 26,  35,  40],\n",
              "           ...,\n",
              "           [ 37,  40,  46],\n",
              "           [  9,  13,  14],\n",
              "           [  4,   7,   5]],\n",
              "  \n",
              "          [[ 23,  34,  39],\n",
              "           [ 27,  38,  43],\n",
              "           [ 25,  36,  41],\n",
              "           ...,\n",
              "           [ 19,  20,  24],\n",
              "           [  4,   6,   3],\n",
              "           [  5,   7,   3]],\n",
              "  \n",
              "          [[ 28,  41,  47],\n",
              "           [ 30,  43,  50],\n",
              "           [ 32,  45,  52],\n",
              "           ...,\n",
              "           [  5,   6,   8],\n",
              "           [  4,   5,   3],\n",
              "           [  7,   8,   7]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 20,  15,  12],\n",
              "           [ 19,  14,  11],\n",
              "           [ 15,  14,  11],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 20,  16,  13],\n",
              "           [ 18,  17,  12],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 21,  17,  12],\n",
              "           [ 20,  18,  11],\n",
              "           ...,\n",
              "           [ 12,  11,   9],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 33,  25,  13],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 28,  25,  52],\n",
              "           [ 29,  25,  58],\n",
              "           [ 23,  20,  42]],\n",
              "  \n",
              "          [[ 33,  25,  14],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 27,  24,  52],\n",
              "           [ 27,  24,  56],\n",
              "           [ 25,  22,  47]],\n",
              "  \n",
              "          [[ 31,  23,  12],\n",
              "           [ 32,  24,  13],\n",
              "           [ 33,  25,  14],\n",
              "           ...,\n",
              "           [ 24,  23,  50],\n",
              "           [ 26,  23,  53],\n",
              "           [ 25,  20,  47]]],\n",
              "  \n",
              "  \n",
              "         [[[ 25,  40,  12],\n",
              "           [ 15,  36,   3],\n",
              "           [ 23,  41,  18],\n",
              "           ...,\n",
              "           [ 61,  82,  78],\n",
              "           [ 92, 113, 112],\n",
              "           [ 75,  89,  92]],\n",
              "  \n",
              "          [[ 12,  25,   6],\n",
              "           [ 20,  37,   7],\n",
              "           [ 24,  36,  15],\n",
              "           ...,\n",
              "           [115, 134, 138],\n",
              "           [149, 168, 177],\n",
              "           [104, 117, 131]],\n",
              "  \n",
              "          [[ 12,  25,  11],\n",
              "           [ 15,  29,   6],\n",
              "           [ 34,  40,  24],\n",
              "           ...,\n",
              "           [154, 172, 182],\n",
              "           [157, 175, 192],\n",
              "           [116, 129, 151]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[100, 129,  81],\n",
              "           [103, 132,  84],\n",
              "           [104, 134,  86],\n",
              "           ...,\n",
              "           [ 97, 128,  84],\n",
              "           [ 98, 126,  84],\n",
              "           [ 91, 121,  79]],\n",
              "  \n",
              "          [[103, 132,  83],\n",
              "           [104, 131,  83],\n",
              "           [107, 135,  87],\n",
              "           ...,\n",
              "           [101, 132,  87],\n",
              "           [ 99, 127,  84],\n",
              "           [ 92, 121,  79]],\n",
              "  \n",
              "          [[ 95, 126,  78],\n",
              "           [ 95, 123,  76],\n",
              "           [101, 128,  81],\n",
              "           ...,\n",
              "           [ 93, 124,  80],\n",
              "           [ 95, 123,  81],\n",
              "           [ 92, 120,  80]]],\n",
              "  \n",
              "  \n",
              "         [[[ 73,  78,  75],\n",
              "           [ 98, 103, 113],\n",
              "           [ 99, 106, 114],\n",
              "           ...,\n",
              "           [135, 150, 152],\n",
              "           [135, 149, 154],\n",
              "           [203, 215, 223]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 84,  89,  97],\n",
              "           [ 68,  75,  81],\n",
              "           ...,\n",
              "           [ 85,  95,  89],\n",
              "           [ 71,  82,  80],\n",
              "           [120, 133, 135]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 90,  95, 100],\n",
              "           [ 62,  71,  74],\n",
              "           ...,\n",
              "           [ 74,  81,  70],\n",
              "           [ 53,  62,  54],\n",
              "           [ 62,  74,  69]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[123, 128,  96],\n",
              "           [132, 132, 102],\n",
              "           [129, 128, 100],\n",
              "           ...,\n",
              "           [108, 107,  88],\n",
              "           [ 62,  60,  55],\n",
              "           [ 27,  27,  28]],\n",
              "  \n",
              "          [[115, 121,  91],\n",
              "           [123, 124,  95],\n",
              "           [129, 126,  99],\n",
              "           ...,\n",
              "           [115, 116,  94],\n",
              "           [ 66,  65,  59],\n",
              "           [ 27,  27,  27]],\n",
              "  \n",
              "          [[116, 120,  90],\n",
              "           [121, 122,  94],\n",
              "           [129, 128, 101],\n",
              "           ...,\n",
              "           [116, 115,  94],\n",
              "           [ 68,  65,  58],\n",
              "           [ 27,  26,  26]]]], dtype=uint8), array([[3],\n",
              "         [8],\n",
              "         [8],\n",
              "         ...,\n",
              "         [5],\n",
              "         [1],\n",
              "         [7]], dtype=uint8)))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DouXNXlSLiGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "z7PFIsd-3ZN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_gVdCwtiSJg",
        "outputId": "a9db175f-5bc9-4f8c-a573-a6e02f76e05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "c1-8y15NkZzw",
        "outputId": "0e97c7c0-4bd4-4c30-e225-7c1067f77d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb7a0092e10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check image shape\n",
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-DF31_uskCz",
        "outputId": "8503f874-b276-4130-9fca-21750602d300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cifar10.data_path = \"data/CIFAR-10/\""
      ],
      "metadata": {
        "id": "UnFOdjfsxQIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten , MaxPooling2D , Dropout \n",
        "\n",
        "model_1 = keras.Sequential()\n",
        "\n",
        "model_1.add(Conv2D(6, (5, 5), padding='same', strides = (1,1) ,activation='relu', input_shape=(32,32,3)))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model_1.add(Conv2D(16, (5, 5), strides=(1,1) , activation='relu'))\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model_1.add(Conv2D(120, (5, 5), strides=(1,1) , activation='relu'))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(units=84, activation='relu'))\n",
        "model_1.add(Dense(units=10, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "yFAUxx1hkS2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNjN-AOIp4bk",
        "outputId": "17f9b0c8-22e8-4632-c510-2f42ef4fdcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 6, 6, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 480)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_1.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_1.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Jry95ousMp",
        "outputId": "8e8648f4-d7f8-4364-deaa-2d8febdbbe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4675 - accuracy: 0.4733 - val_loss: 1.4435 - val_accuracy: 0.4911\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3264 - accuracy: 0.5289 - val_loss: 1.3238 - val_accuracy: 0.5333\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2369 - accuracy: 0.5632 - val_loss: 1.2706 - val_accuracy: 0.5598\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1715 - accuracy: 0.5886 - val_loss: 1.3331 - val_accuracy: 0.5441\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1174 - accuracy: 0.6071 - val_loss: 1.2558 - val_accuracy: 0.5715\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate=0.001\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_2.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b-C4S7D13GJ",
        "outputId": "73160401-6302-4e79-81ce-63cdd9a20f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0708 - accuracy: 0.6227 - val_loss: 1.2577 - val_accuracy: 0.5772\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0124 - accuracy: 0.6446 - val_loss: 1.2786 - val_accuracy: 0.5800\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9818 - accuracy: 0.6557 - val_loss: 1.2288 - val_accuracy: 0.5940\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9379 - accuracy: 0.6701 - val_loss: 1.2832 - val_accuracy: 0.5757\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9109 - accuracy: 0.6800 - val_loss: 1.2503 - val_accuracy: 0.5772\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate=0.0001\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_3.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_3.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFTDGACW5dam",
        "outputId": "db487fb4-2457-4a72-9cff-d02d1774de69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6765 - accuracy: 0.7594 - val_loss: 1.2615 - val_accuracy: 0.6143\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6107 - accuracy: 0.7821 - val_loss: 1.2950 - val_accuracy: 0.6144\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5765 - accuracy: 0.7946 - val_loss: 1.3262 - val_accuracy: 0.6154\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5495 - accuracy: 0.8047 - val_loss: 1.3876 - val_accuracy: 0.6097\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5247 - accuracy: 0.8134 - val_loss: 1.4348 - val_accuracy: 0.6048\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 32\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_4.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_4.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nh7kbVk1jNg",
        "outputId": "0fd8d70f-c804-485e-a610-07d4269e6e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5036 - accuracy: 0.8206 - val_loss: 1.4621 - val_accuracy: 0.6094\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4822 - accuracy: 0.8290 - val_loss: 1.5539 - val_accuracy: 0.6056\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4626 - accuracy: 0.8373 - val_loss: 1.5877 - val_accuracy: 0.6049\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4449 - accuracy: 0.8444 - val_loss: 1.6555 - val_accuracy: 0.6018\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4260 - accuracy: 0.8523 - val_loss: 1.7042 - val_accuracy: 0.5988\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  batch_size = 16\n",
        "##learning_rate=0.0001\n",
        "\n",
        "\n",
        "optm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_5.compile(optimizer=optm,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_5.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25, batch_size = 16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGTYr-Z6ncO",
        "outputId": "a0e8f282-add0-4465-cad0-d79615fff6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.4258 - accuracy: 0.8501 - val_loss: 1.7356 - val_accuracy: 0.6011\n",
            "Epoch 2/5\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.4048 - accuracy: 0.8591 - val_loss: 1.7953 - val_accuracy: 0.5962\n",
            "Epoch 3/5\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.3858 - accuracy: 0.8655 - val_loss: 1.9065 - val_accuracy: 0.5975\n",
            "Epoch 4/5\n",
            "3125/3125 [==============================] - 11s 4ms/step - loss: 0.3666 - accuracy: 0.8738 - val_loss: 2.0322 - val_accuracy: 0.5930\n",
            "Epoch 5/5\n",
            "3125/3125 [==============================] - 12s 4ms/step - loss: 0.3478 - accuracy: 0.8812 - val_loss: 2.0740 - val_accuracy: 0.5939\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 2, 2, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                40404     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,246\n",
            "Trainable params: 92,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHg-wCAhmpxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten , MaxPooling2D , Dropout \n",
        "\n",
        "input_shape=(32,32,3)\n",
        "model_fd = keras.Sequential()\n",
        "keras.Input(input_shape)\n",
        "model_fd.add(Dense(units=6, activation='relu'))\n",
        "model_fd.add(Dense(units=16, activation='relu'))\n",
        "model_fd.add(Dense(units=120, activation='relu'))\n",
        "model_fd.add(Dense(units=84, activation='relu'))\n",
        "model_fd.add(Flatten())\n",
        "model_fd.add(Dense(units=10, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "1Nssktboufky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model_fd.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "#train the model\n",
        "model_fd.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25 , batch_size= 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Otm4BBzoJub",
        "outputId": "436c1945-d1db-492d-a9b1-98b437e8e741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "391/391 [==============================] - ETA: 0s - loss: 10.0861 - accuracy: 0.1788"
          ]
        }
      ]
    }
  ]
}